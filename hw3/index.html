<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    background-color: white;
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
  kbd {
    color: #121212;
  }
</style>
<title>CS 184 Path Tracer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2023</h1>
<h1 align="middle">Project 3-1: Path Tracer</h1>
<h2 align="middle">YOUR NAME: Silu Chu</h2>

<!-- Add Website URL -->
<h2 align="middle"><a href="TODO">Website URL: https://cal-cs184-student.github.io/hw-webpages-sp24-tsuyu76/hw3/index.html</a></h2>

<br><br>


<div align="center">
  <table style="width=100%">
      <tr>
          <td align="middle">
          <img src="images/example_image.png" width="480px" />
          <figcaption align="middle">Results Caption: my bunny is the bounciest bunny</figcaption>
      </tr>
  </table>
</div>

<p>All of the text in your write-up should be <em>in your own words</em>. If you need to add additional HTML features to this document, you can search the <a href="http://www.w3schools.com/">http://www.w3schools.com/</a> website for instructions. To edit the HTML, you can just copy and paste existing chunks and fill in the text and image file names appropriately.</p>
<o>The website writeup is intended to be a self-contained walkthrough of the assignment: we want this to be a piece of work which showcases your understanding of relevant concepts through both mesh images as well as written explanations about what you did to complete each part of the assignment. Try to be as clear and organized as possible when writing about your own output files or extensions to the assignment. We want to understand what you've achieved and how you've done it!</p> 
<p>If you are well-versed in web development, feel free to ditch this template and make a better looking page.</p>


<p>Here are a few problems students have encountered in the past. Test your website on the instructional machines early!</p>
<ul>
<li>Your main report page should be called index.html.</li>
<li>Be sure to include and turn in all of the other files (such as images) that are linked in your report!</li>
<li>Use only <em>relative</em> paths to files, such as <pre>"./images/image.jpg"</pre>
Do <em>NOT</em> use absolute paths, such as <pre>"/Users/student/Desktop/image.jpg"</pre></li>
<li>Pay close attention to your filename extensions. Remember that on UNIX systems (such as the instructional machines), capitalization matters. <pre>.png != .jpeg != .jpg != .JPG</pre></li>
<li>Be sure to adjust the permissions on your files so that they are world readable. For more information on this please see this tutorial: <a href="http://www.grymoire.com/Unix/Permissions.html">http://www.grymoire.com/Unix/Permissions.html</a></li>
<li>And again, test your website on the instructional machines early!</li>
</ul>


<p>Here is an example of how to include a simple formula:</p>
<p align="middle"><pre align="middle">a^2 + b^2 = c^2</pre></p>
<p>or, alternatively, you can include an SVG image of a LaTex formula.</p>

<div>

<h2 align="middle">Overview</h2>
<p>
  I've implemented the method of generating camera rays, sampling pixels, building up BVH binary tree, intersection tests, and ray tracing. These methods work together to render a high quality image with fine global illumination.
</p>
<p>
  It took me some time to understand the path of rays inversely because it comes out from the camera, which is really a key point in ray tracing functions, especially in the recursion of estimating indirect illumination.
</p>
<p>
  I constructed the functions badly at first, which took me extremely long time to render, so I had to spend a lot of time and effort to revise the logic. But this also gave me useful experience on constructing an efficient algorithm. I think I can do better in the future.
</p>
<br>

<h2 align="middle">Part 1: Ray Generation and Scene Intersection (20 Points)</h2>
<!-- Walk through the ray generation and primitive intersection parts of the rendering pipeline.
Explain the triangle intersection algorithm you implemented in your own words.
Show images with normal shading for a few small .dae files. -->

<h3>
  Walk through the ray generation and primitive intersection parts of the rendering pipeline.
</h3>
<p>
  ray generation: 
</p>
<p>
  generating camera rays: 
</p>
<p>
  It finds the corresponding coordinate of a point on the image in camera space , generate the ray from camera position to this point, and transport it into world space so that we can directly trace it.
</p>
<p>
  I implemented it by first calculating the corresponding coordinate of the given coordinate in camera space according to the picture in the spec, then transport it into world space using the c2w matrix, generate the ray using world space coordinates and initialize some parameters.
</p>
<p>
  generating pixel samples: 
</p>
<p>
  It randomly samples points in a pixel for us to generate rays from, using Monte Carlo estimation to collect and average the illumination to the decide the color of a pixel.
</p>
<p>
  I implemented it with a loop of num_samples. For each loop I generate a random position in the sample pixel then normalize it to (x,y)∈[0,1]×[0,1]. I then pass the normalized coordinate to generate_ray function, call the est_radiance_global_illumination function to get the radiance of it, and update the data of the pixel with the estimated radiance.
</p>
<p>
  primitive intersection:
</p>
<p>
  ray-triangle intersection:
</p>
<p>
  It tests whether a ray intersects with a triangle. If intersects, some parameters should be updated for future use.
</p>
<p>
  I implemented it based on Möller Trumbore Algorithm introduced in the lecture.  If the intersection point of the ray and the plane lies in the triangle, then intersects. Despite of the algorithm, arranging the judgments to terminate as early as possible also has a huge influence on rendering time.
</p>
<p>
  ray-sphere intersection: 
</p>
<p>
  It tests whether a ray intersects with a sphere. If intersects, some parameters should be updated for future use.
</p>
<p>
  I implemented it according to the reference slide and the spec. It has two intersection points so we must spend some time deciding which one to choose.
</p>
<br>

<h3>
  Explain the triangle intersection algorithm you implemented in your own words.
</h3>
<p>
  I implemented the Möller Trumbore Algorithm. It generally calculates the barycentric coordinate of the intersection point in the triangle, but it is optimized to reduce the time complexity. If the ray is parallel to the plane then no intersection. If the calculated coordinate is outside the triangle then no intersection. Else intersects and parameters are updated.
</p>
<br>

<h3>
  Show images with normal shading for a few small .dae files.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/Picture1-3-1.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
      <td>
        <img src="images/Picture1-3-2.png" align="middle" width="400px"/>
        <figcaption>banana.dae</figcaption>
      </td>
      <td>
        <img src="images/Picture1-3-3.png" align="middle" width="400px"/>
        <figcaption>bench.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/Picture1-3-4.png" align="middle" width="400px"/>
        <figcaption>building.dae</figcaption>
      </td>
      <td>
        <img src="images/Picture1-3-5.png" align="middle" width="400px"/>
        <figcaption>CBspheres.dae</figcaption>
      </td>
      <td>
        <img src="images/Picture1-3-6.png" align="middle" width="400px"/>
        <figcaption>teapot.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


<h2 align="middle">Part 2: Bounding Volume Hierarchy (20 Points)</h2>
<!-- Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis. -->

<h3>
  Walk through your BVH construction algorithm. Explain the heuristic you chose for picking the splitting point.
</h3>
<p>
  It is based on recursion to create a binary tree, in which each node stores a bounding box. It gets all the primitives in the current node, fix out the bounding box and split it into two parts, and store the primitives in these two parts into its two child nodes, and runs recursively until there are only a certain number of primitives in a node.
</p>
<p>
  heuristic: find the longest dimension of the bounding box and split it from the half of this axis.
</p>

<h3>
  Show images with normal shading for a few large .dae files that you can only render with BVH acceleration.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/Picture2-2-1.png" align="middle" width="400px"/>
        <figcaption>CBlucy.dae</figcaption>
      </td>
      <td>
        <img src="images/Picture2-2-2.png" align="middle" width="400px"/>
        <figcaption>maxplanck.dae</figcaption>
      </td>
      <td>
        <img src="images/Picture2-2-3.png" align="middle" width="400px"/>
        <figcaption>beast.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/Picture2-2-4.png" align="middle" width="400px"/>
        <figcaption>CBdragon.dae</figcaption>
      </td>
      <td>
        <img src="images/Picture2-2-5.png" align="middle" width="400px"/>
        <figcaption>blob.dae</figcaption>
      </td>
      <td>
        <img src="images/Picture2-2-6.png" align="middle" width="400px"/>
        <figcaption>peter.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Compare rendering times on a few scenes with moderately complex geometries with and without BVH acceleration. Present your results in a one-paragraph analysis.
</h3>
<p>
  When traversing the binary tree, if the bounding box in a parent node doesn’t intersect, then all the child nodes can be ignored, so it can avoid a lot of redundant tests to save time.
</p>
<br>

<h2 align="middle">Part 3: Direct Illumination (20 Points)</h2>
<!-- Walk through both implementations of the direct lighting function.
Show some images rendered with both implementations of the direct lighting function.
Focus on one particular scene with at least one area light and compare the noise levels in soft shadows when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, not uniform hemisphere sampling.
Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis. -->

<h3>
  Walk through both implementations of the direct lighting function.
</h3>
<p>
  Direct Lighting with Uniform Hemisphere Sampling:
</p>
<p>
  Sampling rays from the hit point and get the emission of the original point. Generate a random vector on the hemisphere around the hit point. Create a new ray according to this vector as the incident light. If the new ray intersects with a emitting point, then the camera receives the radiance, and reflects some color on the image. Repeating this for num_samples times and get the average radiance. As it’s integrated on half-hemisphere, the result should be multiplied by 2PI. 
</p>
<p>
  Direct Lighting by Importance Sampling Lights: 
</p>
<p>
  Directly sample the lights. It generates a ray from the hit point to a random light source point, and calculates its reflect radiance. If this ray hits somewhere, then it means the light cannot arrive the camera after hitting this point, so there is considered to be a shadow. If it does hit the light source, then add the radiance to the sample pixel.
</p>

<h3>
  Show some images rendered with both implementations of the direct lighting function.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <!-- Header -->
    <tr align="center">
      <th>
        <b>Uniform Hemisphere Sampling</b>
      </th>
      <th>
        <b>Light Sampling</b>
      </th>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/Picture3-2-1.png" align="middle" width="400px"/>
        <figcaption>16 light rays | 8 samples per pixel</figcaption>
      </td>
      <td>
        <img src="images/Picture3-2-2.png" align="middle" width="400px"/>
        <figcaption>16 light rays | 8 samples per pixel</figcaption>
      </td>
    </tr>
    <br>
    <tr align="center">
      <td>
        <img src="images/Picture3-2-3.png" align="middle" width="400px"/>
        <figcaption>16 light rays | 8 samples per pixel</figcaption>
      </td>
      <td>
        <img src="images/Picture3-2-4.png" align="middle" width="400px"/>
        <figcaption>16 light rays | 8 samples per pixel</figcaption>
      </td>
    </tr>
    <br>
  </table>
</div>
<br>

<h3>
  Focus on one particular scene with at least one area light and compare the noise levels in <b>soft shadows</b> when rendering with 1, 4, 16, and 64 light rays (the -l flag) and with 1 sample per pixel (the -s flag) using light sampling, <b>not</b> uniform hemisphere sampling.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/Picture3-3-1.png" align="middle" width="200px"/>
        <figcaption>1 Light Ray (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/Picture3-3-2.png" align="middle" width="200px"/>
        <figcaption>4 Light Rays (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/Picture3-3-3.png" align="middle" width="200px"/>
        <figcaption>16 Light Rays (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/Picture3-3-4.png" align="middle" width="200px"/>
        <figcaption>64 Light Rays (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<p>
  As the number of light rays increases, the noise reduces.
</p>
<br>

<h3>
  Compare the results between uniform hemisphere sampling and lighting sampling in a one-paragraph analysis.
</h3>
<p>
  Lighting sampling is much less noisy than uniform hemisphere sampling. In uniform hemisphere sampling, many of the generated rays just cannot hit the light source and hence cannot contribute to the estimation of radiance. Lighting sampling makes much better use of the data. Every ray sampled must hit at some point and even if it cannot reach the camera, it is considered to be in shadow and is still a useful information. As the number of samples are kept same, the efficiency of lighting sampling is much better.
</p>
<br>


<h2 align="middle">Part 4: Global Illumination (20 Points)</h2>
<!-- Walk through your implementation of the indirect lighting function.
Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
You will probably want to use the instructional machines for the above renders in order to not burn up your own computer for hours. -->

<h3>
  Walk through your implementation of the indirect lighting function.
</h3>
<p>
  It is based on the method of direct lighting sampling, and runs recursively to reach more bounces. I first decided the terminate condition. If the depth reduces to 1, then it should estimate the direct lighting and return. Some other terminate conditions also help to save time, such as a ray which doen’t intersect with any point, or a point behind the light source. Then I construct the recursion step. I generate a new reflected ray with depth-1. If it intersects with some point, then we should continue the recursion to keep track of it. For Russian roulette, just add the coin_flip function to the terminate condition would be effective.
</p>
<br>

<h3>
  Show some images rendered with global (direct and indirect) illumination. Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/Picture4-2-1.png" align="middle" width="400px"/>
        <figcaption>CBbunny.dae</figcaption>
      </td>
      <td>
        <img src="images/Picture4-2-2.png" align="middle" width="400px"/>
        <figcaption>CBempty.dae</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/Picture4-2-3.png" align="middle" width="400px"/>
        <figcaption>CBspheres.dae</figcaption>
      </td>
      <td>
        <img src="images/Picture4-2-4.png" align="middle" width="400px"/>
        <figcaption>bench.dae</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>

<h3>
  Pick one scene and compare rendered views first with only direct illumination, then only indirect illumination. Use 1024 samples per pixel. (You will have to edit PathTracer::at_least_one_bounce_radiance(...) in your code to generate these views.)
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/Picture4-3-1.png" align="middle" width="400px"/>
        <figcaption>Only direct illumination (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/Picture4-3-2.png" align="middle" width="400px"/>
        <figcaption>Only indirect illumination (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
  Direct illuminations are all the same and indirect illuminations cumulate as m increases. Indirect illuminations converge in the lower part.
</p>
<br>

<h3>
  For CBbunny.dae, compare rendered views with max_ray_depth set to 0, 1, 2, 3, and 100 (the -m flag). Use 1024 samples per pixel.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/Picture4-6-1.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 0 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/Picture4-6-2.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 1 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/Picture4-6-3.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 2 (CBbunny.dae)</figcaption>
      </td>
      <td>
        <img src="images/Picture4-6-4.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 3 (CBbunny.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/Picture4-6-6.png" align="middle" width="400px"/>
        <figcaption>max_ray_depth = 100 (CBbunny.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
  In the 2nd and 3rd bounce the bunny is reflecting some color of the wall, and the wall is reflecting some color of the bunny. It better simulates the effect of the environment and is closer to the realistic. Also more pixels will have more accurate color so the image becomes less noisy.
</p>
<br>

<h3>
  Pick one scene and compare rendered views with various sample-per-pixel rates, including at least 1, 2, 4, 8, 16, 64, and 1024. Use 4 light rays.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/Picture4-7-1.png" align="middle" width="400px"/>
        <figcaption>1 sample per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/Picture4-7-2.png" align="middle" width="400px"/>
        <figcaption>2 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/Picture4-7-3.png" align="middle" width="400px"/>
        <figcaption>4 samples per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/Picture4-7-4.png" align="middle" width="400px"/>
        <figcaption>8 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/Picture4-7-5.png" align="middle" width="400px"/>
        <figcaption>16 samples per pixel (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/Picture4-7-6.png" align="middle" width="400px"/>
        <figcaption>64 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/Picture4-7-7.png" align="middle" width="400px"/>
        <figcaption>1024 samples per pixel (example1.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>
<p>
  the noise reduces as number of samples per pixel increases
</p>
<br>


<h2 align="middle">Part 5: Adaptive Sampling (20 Points)</h2>
<!-- Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
Pick one scene and render it with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth. -->

<h3>
  Explain adaptive sampling. Walk through your implementation of the adaptive sampling.
</h3>
<p>
  If the radiance in a sample buffer is converged then it is not necessary to keep track of it an can terminate early. This increases the rendering speed and does not effect the quality of the image much, and makes it possible to render in high level.
</p>
<p>
  I implemented it according to the spec, modifying the sample pixel method. I added the necessary parameters and calculated to make up the early terminate condition, and save the data of sampling times to the sample rate image.
</p>
<br>

<h3>
  Pick two scenes and render them with at least 2048 samples per pixel. Show a good sampling rate image with clearly visible differences in sampling rate over various regions and pixels. Include both your sample rate image, which shows your how your adaptive sampling changes depending on which part of the image you are rendering, and your noise-free rendered result. Use 1 sample per light and at least 5 for max ray depth.
</h3>
<!-- Example of including multiple figures -->
<div align="middle">
  <table style="width:100%">
    <tr align="center">
      <td>
        <img src="images/Picture5-2-1.png" align="middle" width="400px"/>
        <figcaption>Rendered image (example1.dae)</figcaption>
      </td>
      <td>
        <img src="images/Picture5-2-2.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (example1.dae)</figcaption>
      </td>
    </tr>
    <tr align="center">
      <td>
        <img src="images/Picture5-2-3.png" align="middle" width="400px"/>
        <figcaption>Rendered image (example2.dae)</figcaption>
      </td>
      <td>
        <img src="images/Picture5-2-4.png" align="middle" width="400px"/>
        <figcaption>Sample rate image (example2.dae)</figcaption>
      </td>
    </tr>
  </table>
</div>
<br>


</body>
</html>
